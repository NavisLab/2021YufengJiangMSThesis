\chapter{绪论}

\section{课题研究的背景与意义}
我们处于一个信息化时代，每个人手中的电子产品每天都会产生大量的视频、音频和图像等数据，如何利用这些数据是一个重要的研究课题。随着计算机硬件性能的迅速发展和计算能力的提高，基于深度学习的计算机视觉研究如火如荼地开展。计算机视觉的研究工作在我们的生活中无处不在，如手机的指纹解锁、交通监控等。在计算机视觉领域，很多问题如超分辨率、图像着色、风格迁移和图像修复等都可以视为输入一张图像，然后将其翻译成相应的输出图像，即从一个域翻译到另一个域。因为一个场景可以有多种表示方式，如RGB图、语义标签图、梯度场图等，所以图像翻译也可定义为在给定足够训练数据的情况下，将场景一种可能的表示翻译成另一种表示的任务。

在早期研究中，卷积神经网络是最常用于各种预测任务的网络结构，虽然卷积神经网络可以通过学习最小化损失函数得到预测结果，且学习过程是自动的，但对于每个任务仍需要人为设计一个特定于此任务的损失，无法做到各种任务通用。为了更好地解决这个问题，我们可能需要一个通用的损失函数。2014年提出的生成对抗网络\cite{goodfellow2014generative}从考虑预测结果与真实数据是否可区分出发，设计了一个损失函数来满足此目标，因为生成对抗网络学习的是一个适应数据的损失函数，所以它可以应用于多数任务。2017年pix2pix\cite{isola2017image}模型首先基于条件生成对抗网络做像素预测任务，提出一个通用的图像到图像翻译框架，自此敲开基于生成对抗网络的图像翻译领域的大门。

计算机视觉中的图像翻译是一个比较广泛的概念，即输入一幅图像，生成相对应的输出图像，并在翻译过程中通过一定的约束使生成样本与真实样本在分布上尽量一致。基于生成对抗网络的图像翻译有很多应用，比如，可以应用于图像去雨、图像着色等低级别任务，只改变图像表面特征的变化，而不会改变图像的内容；可以应用于季节变化、白天黑夜变化、梵高风格化和木炭风格化，在保证内容一致的情况下，对纹理做一定变化；可以应用于超分辨率重建，提高生成图像质量；可以应用于图像分割、卫星图像转地图，将真实图像映射为抽象图像，体现了图像翻译在多到少映射上的应用；还可以应用于图像修复、文字变图像等。

随着研究的深入，人们发现两个域之间存在较大形状差异时难以实现翻译，这限制了图像翻译的能力。为了解决此问题，研究者们从各个角度提出自己的工作，如引入注意力机制以确定两个域相差较大的区域、将图像映射至外表空间和几何空间以分别实现外表和几何的翻译。这些工作仅对一个目标做翻译，但生活中经常有多个目标同时存在的情况，我们的目的是将图像翻译扩展至多目标形变这一极具挑战性的任务中，从而将其适用性提高到一个新的水平。基于生成对抗网络的图像翻译因其通用性，有广阔的发展空间，不仅可应用于空气中的图像，也可以应用于水下图像，我们输入一张水下图像，并将其翻译至清晰的图像，可看作水下图像清晰化，水下图像清晰化任务将图像翻译从空气中的图像应用至水下图像，进一步扩大了图像翻译的应用范围。

\section{国内外研究现状}

\subsection{生成对抗网络的研究现状}
生成对抗网络（GAN）自2014年由Goodfellow等人\cite{goodfellow2014generative}提出后便引起学术界的关注，越来越多的研究者将其用于图像生成，并探索其它应用领域。生成对抗网络，顾名思义，是通过对抗的方式学习真实数据的分布，对抗需要至少两方相对，因此GAN主要由两部分组成：生成器和判别器。在训练的时候，生成器的目的是尽可能生成以假乱真的样本，判别器则尽可能判别生成样本和真实样本，二者在训练中使生成样本的分布逐渐接近真实样本的分布。目前对GAN的研究可分为两个方向，一个是研究GAN模型训练等理论问题，试图解决训练不稳定和模式崩塌等问题，二是研究GAN的应用，如GAN在图像生成、对象检测或其它领域的应用。

因为训练方式是对抗的，所以在训练时容易出现模型崩溃的情况，需要时刻注意生成器和判别器的训练程度是否对等。Radford等人\cite{radford2015unsupervised}提出的DCGAN将卷积神经网络（CNN）引入GAN中，向CNN的网络拓扑结构加一系列约束使之可稳定训练，同时利用CNN更强的拟合和表达能力，生成更高质量的图像。DCGAN对GAN的改进集中在网络结构，Arjovsky等人\cite{arjovsky2017wasserstein}提出的WGAN则主要集中于损失函数的改进以稳定训练，WGAN认为不应该像原始的GAN一样用JS散度，而应用wassertein距离衡量二者之间的距离。因WGAN受lipschitz连续性条件的限制，所以Gulrajani等人\cite{gulrajani2017improved}提出的WGAN-GP在WGAN的基础上加入梯度惩罚，避免梯度消失和梯度爆炸，收敛速度更快且无需过多关注调参问题，增强训练稳定性。Mao等人\cite{mao2017least}认为相比较JS散度，最小二乘可以使生成分布尽可能逼近决策边界，更能拉进生成样本与真实样本之间的距离，因此提出的LSGAN用最小二乘作为损失函数，可以生成更逼真、更多样的结果。

除了GAN训练不稳定和模式崩塌的问题，模型压缩、预训练模型的利用和泛化等问题也纳入研究行列中。Li等人\cite{li2020gan}提出一个通用的压缩框架以做到既不降低图像质量，又能减少条件生成对抗网络（CGAN\cite{mirza2014conditional}）的计算时间和模型大小。尽管GAN在图像生成中取得令人信服的结果，但对已训练好的模型的重利用仍存在挑战。Gu等人\cite{gu2020image}提出一种新的逆映射方法，从已训练好的GAN模型入手，将其作为先验去处理图像着色、图像修复等多种任务。Bau等人\cite{bau2020rewriting}研究模型重写，提出一种公式，通过操纵深层网络中的一层作为线性联想存储器来改变期望，旨在添加、删除和更改预先训练的深层网络的语义和物理规则。

GAN可以与迁移学习和多模态学习等结合，应用于计算机视觉、图像处理等领域。Ledig等人\cite{ledig2017photo}将GAN引入超分辨率任务，提出的模型可在提升4倍分辨率的情况下恢复细小的纹理细节，增加逼真度。Pathak等人\cite{pathak2016context}结合编码器与解码器结构和GAN，提出一种基于上下文像素预测的非配对算法，通过对视觉特征的学习以填补图像中缺失的区域，GAN在此学习图像特征并起到精细化生成图像修复区域的作用。Vondrick等人\cite{vondrick2016generating}基于GAN提出一个视频生成模型，从大量没有标签的视频中获取动态场景的先验信息，生成一些短小但质量高的视频，模型学习到的特征还可用于图像分类。Wu等人\cite{wu2016learning}提出三维生成对抗网络，建立了一个从低维空间到三维空间的映射，可生成三维物体。除以上所列，图像翻译也是GAN的应用热点，GAN在此领域几乎无所不能。

\subsection{图像翻译的研究现状}

% 图像翻译根据是否需要成对数据分为有监督图像翻译和无监督图像翻译，
2017年，Isola等人\cite{isola2017image}基于条件生成对抗网络提出一个通用的图像翻译框架pix2pix，能够实现语义分割图转街景图、边缘图转真实图、卫星图转地图、图像着色等任务。针对配对图像翻译任务中生成图像质量不高、局部伪影的问题，Wang等人\cite{wang2019discriminative}提出的DRPAN采用判别区域对抗学习的方式，提出了一个用于改善图像翻译效果的修正器，可生成高质量的高分辨率图像。Park等人\cite{park2019semantic}提出的SPADE在给定语义分割图的情况下利用所设计的空间自适应归一化合成逼真的图像。
% Zhu等人提出的SEAN\cite{zhu2020sean}利用分割掩码图像控制生成图像的合成，提出一个语义区域自适应归一化，将区域风格编码和分割掩码作为输入，实现了对

上述三个工作需要大量的配对数据用于训练，是配对图像翻译，但大多数任务并没有配对数据集可用，对此，Zhu等人\cite{zhu2017unpaired}提出的CycleGAN、Yi等人\cite{yi2017dualgan}提出的DualGAN和Kim等人\cite{kim2017learning}提出的DiscoGAN都采用循环一致性损失训练网络，保证生成样本与输入样本的合理对应。Liu等人\cite{liu2017unsupervised}提出的UNIT除了循环一致性思想外，还提出一个共享潜在空间假设，假定来自两个域的图像可以被映射到共享潜在空间中相同的潜码，并证明共享潜在空间约束包含循环一致性约束。

在图像翻译的过程中，我们希望一张图像不局限于翻译到一张图像，而是有多样的输出。Zhu等人\cite{zhu2017toward}将生成对抗网络（GAN\cite{goodfellow2014generative}）和变分自编码器（VAE\cite{kingma2013auto}）结合，提出的BicycleGAN在输出和潜在空间之间加双向映射，可在配对数据集上实现图像的多样性。在非配对图像翻译方面，Huang等人\cite{huang2018multimodal}提出的MUNIT将图像分解到域不变的内容隐空间和特定于域的风格隐空间，通过将两个风格隐空间中随机采样的多个风格编码与内容编码结合，实现多模态图像翻译。Lee等人\cite{lee2018diverse}提出的DRIT除了将图像分解外，为了更好的分离内容编码和属性编码，还提出权重共享和内容判别策略。Mao等人\cite{mao2019mode}提出的MSGAN提出模式搜寻正则化项，最大化生成图像之间的距离与隐向量之间的距离的比值，从而解决模式崩塌问题，生成更多样的结果。
% DSMAP\cite{chang2020domain}通过将域不变内容空间中的特征重映射为特定于域的内容特征，进一步分离内容空间，可以实现更彻底的风格迁移。

当两个域存在较大形状变化时，如马到长颈鹿的翻译，上述模型均不能实现较好翻译，针对此问题，研究者们从各个角度提出解决方法。Gokaslan等人\cite{gokaslan2018improving}认为处理形变问题需要使用来自整个图像的空间信息，保持全局形状和局部纹理的一致性，因此在基于图像块的判别器中加入空洞卷积，使判别器对每个像素的判别都由全局上下文决定。Wu等人\cite{wu2019transgaga}提出的TransGaGa通过分解的方式，将图像分解到外表隐空间和几何隐空间的笛卡尔积上，分别建立外表和几何的翻译，为了使网络学习两个隐空间独立但互补的表示，提出了几何先验损失和条件VAE损失。Kim等人\cite{kim2019u}提出的U-GAT-IT引入注意力机制，通过卷积神经网络确定分类依据的位置，使模型更关注能够区分两个域的区域，从而实现翻译。随着单目标形变图像翻译研究的深入，Mo等人\cite{mo2018instagan}不再局限于单目标翻译，转而研究多目标形变图像翻译，如将一张图像上的多只绵羊翻译为多只长颈鹿，提出的InstaGAN利用实例分割图，在保证背景不变的情况下对多目标进行翻译。

随着图像翻译在低级视觉任务上的成功，研究者们尝试将图像翻译应用于水下图像中。Fabbri等人\cite{fabbri2018enhancing}提出的UGAN利用CycleGAN在非配对水下数据集中训练，将未失真的水下图像与生成的失真水下图像配对，通过基于条件生成对抗网络的图像翻译模型实现图像增强。Lu等人\cite{lu2019multi}提出的MCycleGAN首先利用暗通道先验获得浑浊水下图像的透射图，然后对浑浊的图像与生成的清晰图像的三个颜色通道施以不同尺寸的滑动窗口来计算两种图像之间的SSIM\cite{wang2004image}损失，从而将水下风格的图像翻译至清晰的图像。Liu等人\cite{liu2019mlfcgan}提出的MLFcGAN先提取多尺度特征，然后用全局特征增强每个尺度的局部特征以做颜色校正，使图像从水下的蓝绿色翻译至正常的颜色。
% Guo等人\cite{guo2019underwater}提出的DenseGAN引入一个多尺度密集块算法，该算法采用密集连接、残差学习和多尺度网络进行水下图像增强，使原始的水下图像翻译为相对清晰的图像。

\section{课题来源}

课题来自国家自然科学基金面上项目“类别不平衡条件下海洋浮游生物图像精细识别及其原位应用研究”（批准号：61771440）和国家自然科学基金面上项目“海洋中小型浮游生物原位光学观测关键技术研究”（批准号：41776113）。

\section{论文组织结构安排}

本文主要关注基于生成对抗网络的图像翻译问题，并将其应用到多目标形变图像翻译和水下图像清晰化两个任务中，具体安排如下：

第一章为绪论部分，该部分主要介绍图像翻译的研究背景、应用价值和意义，并对生成对抗网络和图像翻译的国内外研究现状做了简要概述。

第二章主要讨论生成对抗网络的基本原理、基于此改进的算法以及生成对抗网络在图像翻译方面的应用，介绍了配对图像翻译和非配对图像翻译，重点介绍了基于循环一致和基于分解表示的图像翻译算法。

第三章介绍了非配对的单目标形变和多目标形变图像翻译，并设计了基于循环一致的多目标形变图像翻译算法，通过将背景、前景形状和前景纹理分开处理，成功地实现形状的变化，并向翻译后的前景添加纹理，最后将前景与背景结合，从而得到多目标形变结果。

第四章讨论了水下图像清晰化问题，首先介绍了水下成像特性，分析水下图像存在的固有问题，提出了一个基于分解表示的模型，将图像分解为色彩隐空间和信息隐空间两部分，并提出特征提取网络和映射网络，以得到更清晰的翻译结果。

第五章对本文所做的工作进行综合讨论和总结，分析所提出方法的不足之处，同时对该方向的未来研究进行展望。
